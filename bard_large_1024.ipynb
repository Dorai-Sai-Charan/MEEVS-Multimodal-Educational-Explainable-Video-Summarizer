{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0880de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Final Average Evaluation Scores:\n",
      "\n",
      "üîπ ROUGE:\n",
      "ROUGE-1:     0.4116\n",
      "ROUGE-2:     0.2019\n",
      "ROUGE-Lsum:  0.3571 \n",
      "\n",
      "üîπ METEOR:    0.2645\n",
      "\n",
      "üîπ BERTScore:\n",
      "Precision:   0.8855\n",
      "Recall:      0.8643\n",
      "F1 Score:    0.8746\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚úÖ Load trained model\n",
    "model_path = \"bart_large_arxiv_model\"  # ‚Üê update this path if different\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# ‚úÖ Load test data\n",
    "dataset = load_dataset(\"ccdv/arxiv-summarization\")\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# ‚úÖ Load metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# ‚úÖ Store results\n",
    "N = 100\n",
    "predictions, references = [], []\n",
    "rouge_1s, rouge_2s, rouge_Ls, rouge_Lsums = [], [], [], []\n",
    "meteor_scores = []\n",
    "bert_precisions, bert_recalls, bert_f1s = [], [], []\n",
    "\n",
    "print(f\"\\nüîç Evaluating on {N} samples...\\n\")\n",
    "for i in tqdm(range(N)):\n",
    "    article = test_data[i][\"article\"]\n",
    "    reference = test_data[i][\"abstract\"]\n",
    "\n",
    "    # Tokenize + generate\n",
    "    inputs = tokenizer(article, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        num_beams=4,\n",
    "        length_penalty=1.1,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    pred = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(reference)\n",
    "\n",
    "    # Compute metrics\n",
    "    rouge_result = rouge.compute(predictions=[pred], references=[reference])\n",
    "    rouge_1s.append(rouge_result[\"rouge1\"])\n",
    "    rouge_2s.append(rouge_result[\"rouge2\"])\n",
    "    rouge_Ls.append(rouge_result[\"rougeL\"])\n",
    "    rouge_Lsums.append(rouge_result[\"rougeLsum\"])\n",
    "\n",
    "    meteor_result = meteor.compute(predictions=[pred], references=[reference])\n",
    "    meteor_scores.append(meteor_result[\"meteor\"])\n",
    "\n",
    "    bert_result = bertscore.compute(predictions=[pred], references=[reference], lang=\"en\")\n",
    "    bert_precisions.append(bert_result[\"precision\"][0])\n",
    "    bert_recalls.append(bert_result[\"recall\"][0])\n",
    "    bert_f1s.append(bert_result[\"f1\"][0])\n",
    "\n",
    "# ‚úÖ Print average scores\n",
    "print(\"\\nüìä Final Average Evaluation Scores:\")\n",
    "print(\"\\nüîπ ROUGE:\")\n",
    "print(f\"ROUGE-1:     {sum(rouge_1s)/N:.4f}\")\n",
    "print(f\"ROUGE-2:     {sum(rouge_2s)/N:.4f}\")\n",
    "print(f\"ROUGE-L:     {sum(rouge_Ls)/N:.4f}\")\n",
    "print(f\"ROUGE-Lsum:  {sum(rouge_Lsums)/N:.4f}\")\n",
    "\n",
    "print(f\"\\nüîπ METEOR:   {sum(meteor_scores)/N:.4f}\")\n",
    "\n",
    "print(\"\\nüîπ BERTScore:\")\n",
    "print(f\"Precision:   {sum(bert_precisions)/N:.4f}\")\n",
    "print(f\"Recall:      {sum(bert_recalls)/N:.4f}\")\n",
    "print(f\"F1 Score:    {sum(bert_f1s)/N:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtubesum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
